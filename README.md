# MatSpray


<p align="left">
  <strong>
    (TODO) G-Buffer-Conditioned Diffusion for Neural Forward Frame Rendering
  </strong>
</p>

‚ö†Ô∏è This is work in progress please don't publish yet (will release Fri. 19 / 00:00 GMT) 


TODO: ADD TRAILER HERE


<p align="center">
    <span> üåê  <a href="https://matspray.jdihlmann.com/"> Project Page </a> </span>&nbsp;&nbsp;&nbsp;
    <span> üìÑ  <a href="http://arxiv.org/abs/2401.01647"> Paper (Arxiv) </a> </span>&nbsp;&nbsp;&nbsp;
  <span>  üì¶  <a href="https://drive.google.com/drive/folders/1znN_KllBKllIY_1PLZUHbnfHsB6KNifR?usp=sharing"> Materials </a> </span>&nbsp;&nbsp;&nbsp;
  <span>  ‚úçüèª
     <a href="https://github.com/cgtuebingen/MatSpray?tab=readme-ov-file#citation"> Citation </a> </span>&nbsp;&nbsp;&nbsp;
</p>

# About
TODO
We propose photorealistic real-time relighting and novel view synthesis of subsurface scattering objects. We learn to reconstruct the shape and translucent appearance of an object within the 3D Gaussian Splatting framework. Our method decomposes the object into its material properties in a PBR like fashion, with an additional neural subsurface residual component. We achieve high-quality rendering results with our deferred shading approach and allow for detailed material editing capabilities.

# Code
TODO
Paper is currently under review, we will realse the code shortly (~ end of october 2024) in a cleaned version. Up until then if you have any questions regarding the project or need material to compare against fast, feel free to contact us. 



# Citation
You can find our paper on [arXiv](https://arxiv.org/), please consider citing, if you find this work useful:

TODO
```
@inproceeding{framediffuser,
author ={Bei√üwenger, Ole and Dihlmann, Jan-Niklas and Lensch, Hendrik P.A.},
title ={FrameDiffuser: G-Buffer-Conditioned Diffusion for Neural Forward Frame Rendering},
booktitle ={arXiv preprint},
year ={2025}
}
